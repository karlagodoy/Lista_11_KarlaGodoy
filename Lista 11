# Lista 11
# Karla Godoy

## Questão 1

# a)

# É um tipo de modelo de regressão binomial. Neste tipo de modelo a variável dependente assume valores
# de 0 ou 1, a depender da(s) variável(is) dependente(s), responsável(is) por predizer o modelo. A relação
# entre a VD e a(s) VI(s) é simples e permite que o modelo seja ajustado por regressão linear.

# b) 
# Os valores estimados (beta) podem ser interpretados como a mudança na probabilidade da variável dependente ser igual a 1.

# c)
# Os coeficientes estimados são interpretados de forma que o aumento de 1% na(s) variável(is) indepente(s) 
# causa um efeito de Beta% na probabilidade da variável dependente ser igual a 1.

# d)
# O principal problema do LPM é que ele assume que a função de probabilidade condicional é linear. Além de 
# trazer 3 problemas: a não normalidade do termo de erro, erros heterocedásticos e previsões potencialmente sem sentido.


## Questão 2

# a)
# É um modelo de regressão onde a variável dependente é binária e o erro do modelo possui distribuição logística, ele é 
# o logaritmo do odds p: [p/(1-p)]. Este modelo cria valores de probabilidade 0 a 1 para de –infinito a +infinito.

# b)
# Os coeficientes estimados apresentam a direção do seu efeito (se positivo ou negativo) de acordo com o seu sinal e o 
# aumento de uma unidade da variável independente causa um aumento na log-odds na variável dependente de B (valor do beta).

# c) 
# Os coeficientes estimados podem ser interpretados da mesma forma que no modelo bivariado, fixados os valores medianos das 
# outras variáveis independentes, seus valores são responsáveis por dar a mudança no log-odds do resultado para um aumento de
# uma unidade na variável preditora.

## Questão 3

# a)
# É um modelo de regressão onde a variável dependente é binária e o erro do modelo possui distribuição normal e a variância do 
# erro é igual a 1. O modelo probit estima a probabilidade de um valor cair em um dos dois possíveis resultados binários.

# b)
# Uma mudança de uma unidade na VI leva a uma mudança B (Beta) no escore z da VD.

# c)
# Assim como para modelos bivariados, o aumento de 1 unidade em uma VI1 dentro da regressão multivariada causa um aumento de Beta1 no score-z.  

# Questão 4
# a) A função logit é bem similar, mas tem caudas mais finas do que a distribuição normal.


# b) Uma variável latente é uma variável que não é observável diretamente (no mundo real), mas uma variável "escondida" que é importante na definição de um modelo. 
# Essas variáveis podem ser inferidas de outras variáveis que são observadas.  Elas aparecem no modelo em forma de resposta binária.

# C) Nos modelos Logit eProbit Então, o impacto marginal de mudar uma variável não é constante. Nestes tipos de modelo a interpretação que deve ser feita quando este 
# se mostra significante é que com um aumento de 1% no Beta apresentado afeta o z-score de (Y = 1) de acordo com o Beta identificado. Se o coeficiente no BVAP é de 0,0923 e
# significativo, isso significa que um aumento de 1% no BVAP aumentará o z-score de Pr (Y = 1) por 0,0923.


## Questão 5

## Baixando os pacotes necessários para a análise 

install.packages("aod")

library(aod)

library(ggplot2)

## Salvando o banco de dados

mydata <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")


## Visualizando as primeiras linhas dos dados

head(mydata)

# admit gre  gpa rank
# 1     0 380 3.61    3
# 2     1 660 3.67    3
# 3     1 800 4.00    1
# 4     1 640 3.19    4
# 5     0 520 2.93    4
# 6     1 760 3.00    2

## Obtendo descrições básicas para o conjunto de dados.

summary(mydata)

# admit             gre             gpa             rank      
# Min.   :0.0000   Min.   :220.0   Min.   :2.260   Min.   :1.000  
# 1st Qu.:0.0000   1st Qu.:520.0   1st Qu.:3.130   1st Qu.:2.000  
# Median :0.0000   Median :580.0   Median :3.395   Median :2.000  
# Mean   :0.3175   Mean   :587.7   Mean   :3.390   Mean   :2.485  
# 3rd Qu.:1.0000   3rd Qu.:660.0   3rd Qu.:3.670   3rd Qu.:3.000  
# Max.   :1.0000   Max.   :800.0   Max.   :4.000   Max.   :4.000  

## Obtendo desvios padrões

sapply(mydata, sd)

# admit         gre         gpa        rank 
# 0.4660867 115.5165364   0.3805668   0.9444602 

## Garantindo que não haja células com 0

xtabs(~admit + rank, data = mydata)

#  rank
# admit  1  2  3  4
# 0 28 97 93 55
# 1 33 54 28 12


# Convertendo a classificação da base em um fator para indicar que a classificação deve ser 
# tratada como uma variável categórica

mydata$rank <- factor(mydata$rank)

# Modelo de regressão logística usando o glm

mylogit <- glm(admit ~ gre + gpa + rank, data = mydata, family = "binomial")

summary(mylogit)

# Call:
#  glm(formula = admit ~ gre + gpa + rank, family = "binomial", 
#      data = mydata)

# Deviance Residuals: 
#  Min       1Q   Median       3Q      Max  
# -1.6268  -0.8662  -0.6388   1.1490   2.0790  

# Coefficients:
#  Estimate Std. Error z value Pr(>|z|)    
# (Intercept) -3.989979   1.139951  -3.500 0.000465 ***
#  gre          0.002264   0.001094   2.070 0.038465 *  
#  gpa          0.804038   0.331819   2.423 0.015388 *  
#  rank2       -0.675443   0.316490  -2.134 0.032829 *  
#  rank3       -1.340204   0.345306  -3.881 0.000104 ***
#  rank4       -1.551464   0.417832  -3.713 0.000205 ***
  ---
#  Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

# (Dispersion parameter for binomial family taken to be 1)

# Null deviance: 499.98  on 399  degrees of freedom
# Residual deviance: 458.52  on 394  degrees of freedom
# AIC: 470.52

# Number of Fisher Scoring iterations: 4

# Podemos observar que tanto gre quanto gpa são estatisticamente significativos, assim como os três termos para rank.
# Os coeficientes de regressão logística dão a mudança nas probabilidades de log do resultado para um aumento de uma unidade na variável preditora.
# Para cada mudança de uma unidade em gre, as probabilidades de entrada (versus não admissão) aumentam em 0.002.
# Para um aumento de uma unidade em gpa, as chances de ser admitido na pós-graduação aumentaram em 0,804.
# As variáveis indicadoras de classificação têm uma interpretação ligeiramente diferente. Por exemplo, ter frequentado uma instituição de graduação 
# com grau 2, em comparação a uma instituição com classificação 1, altera as chances de registro de admissão em -0.675.

## Obtendo intervlos de confiança dos coeficientes estimados 

## Usando a probabilidade em Log

confint(mylogit)

#                 2.5 %   97.5 %
# (Intercept) -6.271620 -1.79255
# gre          0.000138  0.00444
# gpa          0.160296  1.46414
# rank2       -1.300889 -0.05675
# rank3       -2.027671 -0.67037
# rank4       -2.400027 -0.75354

## Usando erros padrão

confint.default(mylogit)

#                2.5 %   97.5 %
# (Intercept) -6.22424 -1.75572
# gre          0.00012  0.00441
# gpa          0.15368  1.45439
# rank2       -1.29575 -0.05513
# rank3       -2.01699 -0.66342
# rank4       -2.37040 -0.73253

## Testando um efeito geral para Rank

wald.test(b = coef(mylogit), Sigma = vcov(mylogit), Terms = 4:6)

# ----------
# 
# Chi-squared test:
# X2 = 20.9, df = 3, P(> X2) = 0.00011

# A estatística do teste qui-quadrado de 20,9, com três graus de 
# liberdade está associada a um valor de p de 0,00011, indicando que o 
# efeito geral da classificação é estatisticamente significativo.

# Testando hipóteses adicionais sobre as diferenças nos coeficientes para os diferentes níveis de classificação. 

# Teste para identificar se o coeficiente para rank = 2 é igual ao coeficiente para rank = 3.

l <- cbind(0, 0, 0, 1, -1, 0)
wald.test(b = coef(mylogit), Sigma = vcov(mylogit), L = l)

# Wald test:
# ----------
# 
# Chi-squared test:
# X2 = 5.5, df = 1, P(> X2) = 0.019

# A estatística do teste qui-quadrado de 5,5 com 1 grau de liberdade está associada com um p- valor de 0,019, indicando 
# que a diferença entre o coeficiente de classificação = 2 e o coeficiente de classificação = 3 é estatisticamente significativa.

# Exponenciando os coeficientes para interpretá-los como odds-ratios

## Apenas odds ratios

exp(coef(mylogit))

# (Intercept)         gre         gpa       rank2       rank3       rank4 
# 0.0185001   1.0022670   2.2345448   0.5089310   0.2617923   0.2119375 

# odds ratios e 95% CI

exp(cbind(OR = coef(mylogit), confint(mylogit)))

#                 OR   2.5 % 97.5 %
# (Intercept) 0.0185 0.00189  0.167
# gre         1.0023 1.00014  1.004
# gpa         2.2345 1.17386  4.324
# rank2       0.5089 0.27229  0.945
# rank3       0.2618 0.13164  0.512
# rank4       0.2119 0.09072  0.471

## Agora podemos dizer que, para um aumento de uma unidade em gpa, as chances de
## ser admitido na pós-graduação (versus não ser admitido) aumentam em um fator de 2,23.

## Calculando a probabilidade prevista de admissão em cada valor de classificação, mantendo gre e gpa em suas médias. 

## Primeiro criamos e visualizamos o quadro de dados.

newdata1 <- with(mydata, data.frame(gre = mean(gre), gpa = mean(gpa), rank = factor(1:4)))

## Observando data frame

newdata1

#   gre  gpa rank
# 1 588 3.39    1
# 2 588 3.39    2
# 3 588 3.39    3
# 4 588 3.39    4

## Criando probbilidades

newdata1$rankP <- predict(mylogit, newdata = newdata1, type = "response")

newdata1

#   gre  gpa rank rankP
# 1 588 3.39    1 0.517
# 2 588 3.39    2 0.352
# 3 588 3.39    3 0.219
# 4 588 3.39    4 0.185

# A saída acima, vemos que a probabilidade prevista de ser aceito em um programa de pós-graduação é de 0,52 para estudantes das 
# instituições de graduação de maior prestígio (classificação = 1) e de 0,18 para alunos das instituições de menor classificação (classificação = 4). e gpa em seus meios.

## crie uma tabela de probabilidades previstas variando o valor de gre e rank. 

## Criando 100 valores de gre entre 200 e 800, em cada valor de rank (ou seja, 1, 2, 3 e 4).

newdata2 <- with(mydata, data.frame(gre = rep(seq(from = 200, to = 800, length.out = 100),
                                              4), gpa = mean(gpa), rank = factor(rep(1:4, each = 100))))

newdata3 <- cbind(newdata2, predict(mylogit, newdata = newdata2, type = "link",
                                    se = TRUE))
newdata3 <- within(newdata3, {
  PredictedProb <- plogis(fit)
  LL <- plogis(fit - (1.96 * se.fit))
  UL <- plogis(fit + (1.96 * se.fit))
})

## Visualiando algumas linhas do banco final

head(newdata3)

#   gre  gpa rank    fit se.fit residual.scale    UL    LL PredictedProb
# 1 200 3.39    1 -0.811  0.515              1 0.549 0.139         0.308
# 2 206 3.39    1 -0.798  0.509              1 0.550 0.142         0.311
# 3 212 3.39    1 -0.784  0.503              1 0.551 0.145         0.313
# 4 218 3.39    1 -0.770  0.498              1 0.551 0.149         0.316
# 5 224 3.39    1 -0.757  0.492              1 0.552 0.152         0.319
# 6 230 3.39    1 -0.743  0.487              1 0.553 0.155         0.322

## Plotando as probabilidades previstas e intervalos de confiança de 95%

ggplot(newdata3, aes(x = gre, y = PredictedProb)) + geom_ribbon(aes(ymin = LL,
                                                                    ymax = UL, fill = rank), alpha = 0.2) + geom_line(aes(colour = rank),
                                                                                                                      size = 1)
## Descobrindo quanto o modelo é adequado 

## Encontrar a diferença no desvio para os dois modelos

with(mylogit, null.deviance - deviance)

# [1] 41.45903

# Os graus de liberdade para a diferença entre os dois modelos é igual ao número de variáveis preditoras no modo:

with(mylogit, df.null - df.residual)

# [1] 5

# P- Valor

with(mylogit, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))

# [1] 7.58e-08

## O qui-quadrado de 41,46 com 5 graus de liberdade e um p-valor associado menor que 0,001 nos 
## diz que nosso modelo como um todo se ajusta significativamente melhor que um modelo vazio. Isso às vezes é chamado de teste de razão de verossimilhança (o desvio de deviance é -2 * log verossimilhança).

## Vendo a probabilidade do log do modelo

logLik(mylogit)

## 'log Lik.' -229 (df=6)

----
  
## QuestÃ£o 6: 
  
  # Instalar e requerer pacotes necessÃ¡rios:
  install.packages("aod")
require(aod)
require(ggplot2)

# Carregar base de dados:
dados <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")

# Converter variÃ¡vel categÃ³rica "rank" para fator:
dados$rank <- factor(dados$rank)

# Checar primeiras linhas da base:
head(dados)

# Checar estatÃ�sticas descritivas da base:
summary(dados)

# Checar variÃ¡vel rank vs admit (a VD da questÃ£o): 
xtabs(~rank + admit, data = dados)

# Gerar regressÃ£o probit (visto que a variÃ¡vel de resposta Ã© binÃ¡ria), VD = admit,
# VIs = gre, gpa e rank:
regprobit <- glm(admit ~ gre + gpa + rank, family = binomial(link = "probit"), 
                 data = dados)

# Sumarizar modelo:
summary(regprobit)

# Gerar intervalo de confianÃ§a para os coeficientes encontrados:
confint(regprobit)

# Testar o efeito da VI "rank":
wald.test(b = coef(regprobit), Sigma = vcov(regprobit), Terms = 4:6)
# Nota-se que o efeito de rank Ã© estatisticamente significante.

# Testar a diferenÃ§a entre os termos 4 e 5 do modelo de regressÃ£o (rank = 2 e 
# rank = 3):
l <- cbind(0, 0, 0, 1, -1, 0)
wald.test(b = coef(regprobit), Sigma = vcov(regprobit), L = l)
# Nota-se que a diferenÃ§a entre os coeficientes de rank = 2 e rank = 3 Ã© 
# estatisticamente significante.

# Criar nova base com probabilidades esperadas das VIs (para criar um "null model"): 
novosdados <- data.frame(gre = rep(seq(from = 200, to = 800, length.out = 100), 
                                   4 * 4), gpa = rep(c(2.5, 3, 3.5, 4), each = 100 * 4), 
                         rank = factor(rep(rep(1:4, each = 100), 4)))

# Checar primeiras linhas da nova base:
head(novosdados)

# Criar quatro plots com as probabilidades esperadas para os diferentes escores
# da VI "gre", um para cada nÃ�vel da VI "gpa" e cada cor de linha representa
# uma categoria de "rank" e IC 95%: 

# Acrescentar valores do erro padrÃ£o dos coeficientes e probabilidade predita
# Ã  base:
novosdados[, c("p", "se")] <- predict(regprobit, novosdados, type = "response", 
                                      se.fit = TRUE)[-3]

# Plotar grÃ¡ficos:
ggplot(novosdados, aes(x = gre, y = p, colour = rank)) + geom_line() + facet_wrap(~gpa)

# Testar a diferenÃ§a entre a variÃ¢ncia dos resÃ�duos do modelo nulo e o construÃ�do: 
with(regprobit, null.deviance - deviance)

# Analisar a diferenÃ§a nos graus de liberdade entre o modelo nulo e o construÃ�do:
with(regprobit, df.null - df.residual)

# Obter p-valor a partir do teste do qui-quadrado:
with(regprobit, pchisq(null.deviance - deviance, df.null - df.residual, 
                       lower.tail = FALSE))


---
  
  
## QuestÃ£o 7
  
# Adicionar valores dos ICs 95% Ã  base:
  novosdados <- within(novosdados, {
    PredictedProb <- novosdados$p
    lwr <- PredictedProb - (1.96 * se)
    upr <- PredictedProb + (1.96 * se)
  })

# Checar base:
head(novosdados)

# Plotar grÃ¡ficos com intervalos de confianÃ§a:
ggplot(novosdados, aes(x = gre, y = PredictedProb)) + 
  geom_ribbon(aes(ymin = lwr, ymax = upr, fill = rank), alpha = 0.2) +
  geom_line(aes(colour = rank), size = 0.7) + facet_wrap(~gpa) 


---

## QuestÃ£o 8
  
# Abrindo pacotes
  if(require(ggplot2) == F) install.packages('ggplot2'); require(ggplot2)

# Abrindo banco de dados
sample <- read.csv("C:/Users/NATHALIA/Documents/CP-Mestrado/AnÃ¡lise de Dados - Davi Moreira/sample.csv", header=T)


## a)
# RegressÃ£o logit com VD hon e VI female
reg <- glm(hon ~ female, family = binomial, data = sample)

# Resumo da regressÃ£o
summary(reg)

# Logit inverso para transformar os coeficientes do modelo em probabilidade
exp( coef(reg) ) /  ( 1 + exp( coef(reg) ) )


## b)
# RegressÃ£o logit com VD hon e VI math
reg2 <- glm(hon ~ math, family = binomial, data = sample)

# Resumo da regressÃ£o
summary(reg2)

# Logit inverso para transformar os coeficientes do modelo em probabilidade
exp( coef(reg2) ) /  ( 1 + exp( coef(reg2) ) )

## c)
# RegressÃ£o logit com VD hon e VI math
reg3 <- glm(hon ~ female + math + read, family = binomial, data = sample)

# Resumo da regressÃ£o
summary(reg3)

## GrÃ¡fico do comportamento do modelo para âfemaleâ em relaÃ§Ã£o a âmathâ, com mÃ©dia de read.

# Probabilidade predita para da admissÃ£o de cada valor de female e math, deixando read na sua mÃ©dia.
sample.2 <- with(sample, data.frame(female, math, read = mean(read)))

# TransformaÃ§Ã£o dos valores previstos e os limites de confianÃ§a em probabilidades.
sample.2 <- cbind(sample.2, predict(reg3, newdata = sample.2, type = "link", se = TRUE))
sample.2 <- within(sample.2, {
  PredictedProb <- plogis(fit)
  LL <- plogis(fit - (1.96 * se.fit))
  UL <- plogis(fit + (1.96 * se.fit))
})

# Colocando female como fator
sample.2$female <- factor(sample.2$female)

# O grÃ¡fico do comportamento do modelo para âfemaleâ em relaÃ§Ã£o a âmathâ, com mÃ©dia de read.
ggplot(sample.2, aes(x = math, y = PredictedProb)) + 
  geom_ribbon(aes(ymin = LL, ymax = UL, fill = female), alpha = 0.2) + 
  geom_line(aes(colour = female))

## d)

# Abrindo pacote 
if(require(rms) == F) install.packages('rms'); require(rms)

# Pseudo-R2 de Nagelkerke
reg3n <- lrm(hon ~ female + math + read, data = sample)

# Resumo da regressÃ£o incluindo o R2 de Nagelkerke
print(reg3n)

## R2 = 0.421 

----

# Questão 9
  
# Instalar e requerer pacotes necessÃ¡rios:

install.packages("foreign")  
install.packages("nnet")
install.packages("ggplot2")
install.packages("reshape2")
install.packages("effects")
install.packages("tidyverse")
  
require(foreign)
require(nnet)
require(ggplot2)
require(reshape2)
require(effects)
require(tidyverse)


# Carregar dados:
ml <- read.dta("https://stats.idre.ucla.edu/stat/data/hsbdemo.dta")

# Analisar variÃ¡veis de interesse:
with(ml, table(ses, prog))

#prog
# ses      general academic vocation
# low         16       19       12
# middle      20       44       31
# high         9       42        7

# Obter estatÃ�sticas descritivas das variÃ¡veis:
with(ml, do.call(rbind, 
                 tapply(write, prog, function(x) c(M = mean(x), SD = sd(x)))))

#                 M       SD
# general  51.33333 9.397775
# academic 56.25714 7.943343
# vocation 46.76000 9.318754

# Definir categoria de referÃªncia ("academic"):
ml$prog2 <- relevel(ml$prog, ref = "academic")

# Gerar regressÃ£o logÃ�stica multinomial:
test <- multinom(prog2 ~ ses + write, data = ml)

# weights:  15 (8 variable)
# initial  value 219.722458 
# iter  10 value 179.982880
# final  value 179.981726 
# converged

# Checar resultados da regressÃ£o:
summary(test)

# Call:
#  multinom(formula = prog2 ~ ses + write, data = ml)

# Coefficients:
#  (Intercept)  sesmiddle    seshigh      write
# general     2.852198 -0.5332810 -1.1628226 -0.0579287
# vocation    5.218260  0.2913859 -0.9826649 -0.1136037

# Std. Errors:
#  (Intercept) sesmiddle   seshigh      write
# general     1.166441 0.4437323 0.5142196 0.02141097
# vocation    1.163552 0.4763739 0.5955665 0.02221996

# Residual Deviance: 359.9635 
# AIC: 375.9635

# Calcular p-valor:
z <- summary(test)$coefficients/summary(test)$standard.errors
p <- (1 - pnorm(abs(z), 0, 1)) * 2
p

# (Intercept) sesmiddle    seshigh        write
# general  0.0144766100 0.2294379 0.02373856 6.818902e-03
# vocation 0.0000072993 0.5407530 0.09894976 3.176045e-07

# Extrair coeficientes do modelo e exponenciar valores, que aponta o "risk ratio"
# relativo para o aumento de uma unidade na VI:
exp(coef(test))

#  (Intercept) sesmiddle   seshigh     write
# general     17.32582 0.5866769 0.3126026 0.9437172
# vocation   184.61262 1.3382809 0.3743123 0.8926116

# Calcular probabilidade predita para cada resultado e checar primeiras linhas:

head(pp <- fitted(test))

# academic   general  vocation
# 1 0.1482764 0.3382454 0.5134781
# 2 0.1202017 0.1806283 0.6991700
# 3 0.4186747 0.2368082 0.3445171
# 4 0.1726885 0.3508384 0.4764731
# 5 0.1001231 0.1689374 0.7309395
# 6 0.3533566 0.2377976 0.4088458

# Analisar mudanÃ§as nas probabilidades preditas. Neste caso, a VI "write" serÃ¡
# mantida constante (em sua mÃ©dia), enquanto serÃ£o analisadas as probabilidades
# preditas para cada um dos nÃ�veis da VI "ses":
dses <- data.frame(ses = c("low", "middle", "high"), write = mean(ml$write))
predict(test, newdata = dses, "probs")

#  academic   general  vocation
# 1 0.4396845 0.3581917 0.2021238
# 2 0.4777488 0.2283353 0.2939159
# 3 0.7009007 0.1784939 0.1206054

# Analisar as probabilidades preditas mÃ©dias para os diferentes valores de "write",
# em cada um dos nÃ�veis da variÃ¡vel "ses":
dwrite <- data.frame(ses = rep(c("low", "middle", "high"), each = 41), 
                     write = rep(c(30:70), 3))

# Criar objeto com probabilidades preditas para cada um dos valores de "ses" e "write":
pp.write <- cbind(dwrite, predict(test, newdata = dwrite, type = "probs", se = TRUE))

# Calcular as probabilidades preditas mÃ©dias para cada nÃ�vel de "ses":
by(pp.write[, 3:5], pp.write$ses, colMeans)

# pp.write$ses: high
# academic   general  vocation 
# 0.6164315 0.1808037 0.2027648 
----------------------------------------------------------------- 
#  pp.write$ses: low
# academic   general  vocation 
# 0.3972977 0.3278174 0.2748849 
----------------------------------------------------------------- 
#  pp.write$ses: middle
# academic   general  vocation 
# 0.4256198 0.2010864 0.3732938

# Utilizar funÃ§Ã£o "melt" do pacote "reshape2" para transformar o objeto "pp.write",
# criado acima, em formato "long":
lpp <- melt(pp.write, id.vars = c("ses", "write"), value.name = "probability")

# Checar primeiras linhas:
head(lpp) 

# Plotar probabilidades preditas para os valores de "write" a cada nÃ�vel de "ses",
# em cada um dos 3 tipos de programa ("academic", "general" ou "vocation") 
ggplot(lpp, aes(x = write, y = probability, colour = ses)) + geom_line() + 
  facet_grid(variable ~ ., scales = "free")


---
  
## Questão 10

ml<- read.dta("https://stats.idre.ucla.edu/stat/data/hsbdemo.dta")

ml$prog2 <- relevel(ml$prog, ref = "academic")

test <- multinom(prog2 ~ ses + write, data = ml)

summary(test)

confint(test)

fit.eff <- effect("ses", test)

testegrafico <- data.frame(fit.eff$model.matrix, fit.eff$prob, fit.eff$lower.prob, 
                           fit.eff$upper.prob)

testegrafico$seslow <- ifelse(testegrafico$sesmiddle == 0 & testegrafico$seshigh == 0,  1, 0)

testegrafico$ses <- ifelse(testegrafico$sesmiddle == 1, "middle", ifelse(testegrafico$seshigh == 1,  "high", "low"))

grupo1 <- gather(testegrafico, response, prob, prob.academic:prob.vocation)
grupo2 <- gather(testegrafico, LB, probLB, L.prob.academic:L.prob.vocation)
grupo3 <- gather(testegrafico, UB, probUB, U.prob.academic:U.prob.vocation)

# selecionando colunas de cada base
grafico <- cbind(grupo1[, 12:14], grupo2[, 13:14], grupo3[, 13:14])

# ajustando levels na nova base
grafico$ses <- factor(grafico$ses, levels = c("low", "middle", "high"))

# gráfico com os intervalos de confiança
ggplot(grafico, aes(x = response, y = prob)) +
  geom_errorbar(aes(ymin = probLB, ymax = probUB), width = 0.2, lty=1, lwd=1, col="red") +
  geom_point(shape=18, size=5, fill="black") +
  facet_wrap(~ses)

## Questão 11

### letra a)
  
# Carregar dados:
ml <- read.dta("https://stats.idre.ucla.edu/stat/data/hsbdemo.dta")

# Analisar variÃ¡veis de interesse:
with(ml, table(ses, prog))

# Obter estatÃ�sticas descritivas das variÃ¡veis:
with(ml, do.call(rbind, tapply(write, prog, function(x) c(M = mean(x),
                                                          SD = sd(x)))))

# Definir categoria de referÃªncia ("vocation"):
ml$prog3 <- relevel(ml$prog, ref = "vocation")

# Gerar regressÃ£o logÃ�stica multinomial:
test2 <- multinom(prog3 ~ ses + write, data = ml)

# Checar resultados da regressÃ£o:
summary(test2)

# Calcular p-valor:
z2 <- summary(test2)$coefficients/summary(test2)$standard.errors
p2 <- (1 - pnorm(abs(z2), 0, 1)) * 2
p2

# Extrair coeficientes do modelo e exponenciar valores, que aponta o "risk ratio"
# (ou razÃ£o do risco) relativo para o aumento de uma unidade na VI:
exp(coef(test2))

# Calcular probabilidade predita para cada resultado e checar primeiras linhas:
head(pp <- fitted(test2))

# Analisar mudanÃ§as nas probabilidades preditas. Neste caso, a VI "write" serÃ¡
# mantida constante (em sua mÃ©dia), enquanto serÃ£o analisadas as probabilidades
# preditas para cada um dos nÃ�veis da VI "ses":
dses2 <- data.frame(ses = c("low", "middle", "high"), write = mean(ml$write))
predict(test2, newdata = dses2, "probs")

# Analisar as probabilidades preditas mÃ©dias para os diferentes valores de "write",
# em cada um dos nÃ�veis da variÃ¡vel "ses":
dwrite2 <- data.frame(ses = rep(c("low", "middle", "high"), each = 41), 
                      write = rep(c(30:70), 3))

# Criar objeto com probabilidades preditas para cada um dos valores de "ses" e "write":
pp.write2 <- cbind(dwrite2, predict(test2, newdata = dwrite2, type = "probs", se = TRUE))

# Calcular as probabilidades preditas mÃ©dias para cada nÃ�vel de "ses":
by(pp.write2[, 3:5], pp.write2$ses, colMeans)

# Utilizar funÃ§Ã£o "melt" do pacote "reshape2" para transformar o objeto "pp.write",
# criado acima, em formato "long":
lpp2 <- melt(pp.write2, id.vars = c("ses", "write"), value.name = "probability")

# Checar primeiras linhas:
head(lpp2) 

# Plotar probabilidades preditas para os valores de "write" a cada nÃ�vel de "ses",
# em cada um dos 3 tipos de programa ("academic", "general" ou "vocation") 
ggplot(lpp2, aes(x = write, y = probability, colour = ses)) + geom_line() + 
  facet_grid(variable ~ ., scales = "free")

# SÃ£o analisados os efeitos do status socioeconÃ´mico ("ses") e das habilidades 
# de escrita ("write", medida pelo escore alcanÃ§ado nesta disciplina) de um aluno 
# sobre a probabilidade deste escolher, no ensino mÃ©dio, programas acadÃªmicos, 
# gerais ou vocacionais. A categoria de referÃªncia da variÃ¡vel de resposta ("prog"),
# neste modelo, Ã© "vocation", ou seja, os coeficientes apresentados para as 
# categorias "general" e "academic" estÃ£o sendo comparados Ã queles encontrados 
# para a categoria "vocation". 

# Ao observar os efeitos da variÃ¡vel "ses", Ã© possÃ�vel concluir que alunos com
# status socioeconÃ´mico alto, comparados aos de nÃ�vel socioeconÃ´mico baixo, tÃªm 
# maior probabilidade de escolher o tipo de programa "acadÃªmico" durante o ensino
# mÃ©dio, quando comparado ao programa do tipo "vocation" e menor probabilidade 
# de escolher programas do tipo "general" do que aqueles do tipo "vocation". 

# Os alunos com nÃ�vel socioeconÃ´mico mÃ©dio, comparados aos de nÃ�vel socioeconÃ´mico
# baixo, tÃªm menor probabilidade de escolher programas dos tipos "general" ou 
# "academic" quando comparados Ã  categoria base "vocation".

# Neste modelo, o p-valor para todos os coeficientes encontrados foi maior do que
# 0.05.

# Ao manter constante a variÃ¡vel "write" Ã© possÃ�vel observar as probabilidades
# preditas para cada nÃ�vel da VI "ses" e tipo de programa (a VD). Para os alunos
# que optam por programas do tipo "vocation", Ã© mais provÃ¡vel que pertenÃ§am Ã  classe 
# socioeconÃ´mica mÃ©dia. Para os que optam por "general", a probabilidade de que 
# pertenÃ§am Ã  classe socioeconÃ´mica baixa Ã© maior. Finalmente, para os que optam
# por programas do tipo "academic", a probabilidade de que pertenÃ§am Ã  classe 
# socioeconÃ´mica alta Ã© maior.

### letra b)

# Carregar dados:
ml <- read.dta("https://stats.idre.ucla.edu/stat/data/hsbdemo.dta")

# Analisar variÃ¡veis de interesse:
with(ml, table(ses, prog))

# Obter estatÃ�sticas descritivas das variÃ¡veis:
with(ml, do.call(rbind, tapply(write, prog, function(x) c(M = mean(x),
                                                          SD = sd(x)))))

# Definir categoria de referÃªncia ("general"):
ml$prog4 <- relevel(ml$prog, ref = "general")

# Gerar regressÃ£o logÃ�stica multinomial:
test3 <- multinom(prog4 ~ ses + write, data = ml)

# Checar resultados da regressÃ£o:
summary(test3)

# Calcular p-valor:
z3 <- summary(test3)$coefficients/summary(test3)$standard.errors
p3 <- (1 - pnorm(abs(z3), 0, 1)) * 2
p3

# Extrair coeficientes do modelo e exponenciar valores, que aponta o "risk ratio"
# relativo para o aumento de uma unidade na VI:
exp(coef(test3))

# Calcular probabilidade predita para cada resultado e checar primeiras linhas:
head(pp <- fitted(test3))

# Analisar mudanÃ§as nas probabilidades preditas. Neste caso, a VI "write" serÃ¡
# mantida constante (em sua mÃ©dia), enquanto serÃ£o analisadas as probabilidades
# preditas para cada um dos nÃ�veis da VI "ses":
dses3 <- data.frame(ses = c("low", "middle", "high"), write = mean(ml$write))
predict(test3, newdata = dses3, "probs")

# Analisar as probabilidades preditas mÃ©dias para os diferentes valores de "write",
# em cada um dos nÃ�veis da variÃ¡vel "ses":
dwrite3 <- data.frame(ses = rep(c("low", "middle", "high"), each = 41), 
                      write = rep(c(30:70), 3))

# Criar objeto com probabilidades preditas para cada um dos valores de "ses" e "write":
pp.write3 <- cbind(dwrite3, predict(test3, newdata = dwrite3, type = "probs", se = TRUE))

# Calcular as probabilidades preditas mÃ©dias para cada nÃ�vel de "ses":
by(pp.write3[, 3:5], pp.write3$ses, colMeans)

# Utilizar funÃ§Ã£o "melt" do pacote "reshape2" para transformar o objeto "pp.write",
# criado acima, em formato "long":
lpp3 <- melt(pp.write3, id.vars = c("ses", "write"), value.name = "probability")

# Checar primeiras linhas:
head(lpp3) 

# Plotar probabilidades preditas para os valores de "write" a cada nÃ�vel de "ses",
# em cada um dos 3 tipos de programa ("academic", "general" ou "vocation") 
ggplot(lpp3, aes(x = write, y = probability, colour = ses)) + geom_line() + 
  facet_grid(variable ~ ., scales = "free")


# Ao observar os efeitos da variÃ¡vel "ses", Ã© possÃ�vel concluir que alunos com
# status socioeconÃ´mico alto, comparados aos de nÃ�vel socioeconÃ´mico baixo,
# tÃªm maior probabilidade de escolher o tipo de programa "acadÃªmico" durante o 
# ensino mÃ©dio, quando comparado ao programa do tipo "general" e tambÃ©m maior 
# probabilidade de escolher programas do tipo "vocation" do que aqueles do tipo 
# "general". 

# Os alunos com nÃ�vel socioeconÃ´mico mÃ©dio, comparados aos de nÃ�vel socioeconÃ´mico
# baixo, tÃªm maior probabilidade de escolher programas dos tipos "vocation" ou 
# "academic" quando comparados Ã  categoria base "general". 

# Com exceÃ§Ã£o do coeficiente do intercepto para "vocation" e de "academic|seshigh"
# que apresentaram p-valor 0.04 e 0.02 respectivamente, todos os outros resultados
# apresentaram p valor maior do que 0.05. 

  
## Questão 12


## Questão 13

setwd("C:/Users/karla/Desktop/Mestrado/Análise de Dados/Lista 11")
## a)

## Carregando Dados

df <- read.dta('nomocc2.dta')

## Criando VariÃ¡vel
df$wkr <- df$occ

df$wkr <- ifelse(df$wkr %in% c('Menial','BlueCol','Craft'),'Manual',as.character(df$wkr))

df$wkr <- as.factor(df$wkr)

## Alterando Categoria de ReferÃªncia
df$wbk <- relevel(df$wkr, ref = "Manual")

## White para factor
df$white <- as.factor(df$white)

## Gerando Modelo
md <- multinom(wbk ~ white + exper,data = df)

## SumÃ¡rio do Modelo
summary(md)

## Visualizando Z values
z_v <- summary(md)$coefficients/summary(md)$standard.errors
z_v

## Interpretando Efeitos de White:
# Ser "branco" aumenta a as probabilidades de ser
# trabalhador profissional e tambÃ©m de ser trabalhador
# whitecol.

## b)

## Gerando PrevisÃµes - exper fixo
prv <- effect('white',md,xlevels = list(exper= 0,1), fixed.predictiors = 'exper',
              given.values = mean(df$exper), se = T) 

to.plot <- data.frame(p.nw = prv$prob[1,],
                      p.wh = prv$prob[2,],
                      se.nw = prv$se.prob[1,],
                      se.wh = prv$se.prob[2,])

par(mfrow = c(1,2))
plot(to.plot$p.nw,to.plot$se.nw,CI = 2,main = 'No white',vertical = F,
         varnames = c('Manual','Prof','WhiteCol'), ylim = c(0,.9),
         cex.var = 1.2, cex.pts = 2, ylab = 'Probabilidades',var.las = 1)

plot(to.plot$p.wh,to.plot$se.wh,CI = 2,main = 'White',vertical = F,
         varnames = c('Manual','Prof','WhiteCol'), ylim = c(0,.9),
         cex.var = 1.2, cex.pts = 2, ylab = 'Probabilidades',var.las = 1)

## Gerando PrevisÃµes - white fixo
# Simulando Dados
ds <- data.frame(exper = c(seq(2,66,length.out = 100),
                           seq(2,66,length.out = 100)),
                 white = c(rep('0',100),rep('1',100)))

# Gerando PrevisÃµes
ppv <- effect('exper',md,xlevels = list(exper = 2:66),fixed.predictiors = 'white', 
              given.values = '1', se = T)


to.plot <- data.frame(ma.prob = ppv$prob[,1],
                      pr.prob = ppv$prob[,2],
                      wh.prob = ppv$prob[,3],
                      ma.se = ppv$se.prob[,1],
                      pr.se = ppv$se.prob[,2],
                      wh.se = ppv$se.prob[,3])

par(mfrow = c(1,3))

plot(to.plot$ma.prob ~ c(2:66), type = 'l',
     main = 'Manual', ylab = 'Probabilidade',
     xlab = 'ExperiÃªncia', col = 'red',
     ylim = c(min(to.plot$ma.prob - 2*to.plot$ma.se),
              max(to.plot$ma.prob + 2*to.plot$ma.se)))

lines(y = to.plot$ma.prob - 2*to.plot$ma.se,x = c(2:66),
      col = 'blue')
lines(y = to.plot$ma.prob + 2*to.plot$ma.se,x = c(2:66),
      col = 'blue')

plot(to.plot$pr.prob ~ c(2:66), type = 'l',
     main = 'Profissional', ylab = 'Probabilidade',
     xlab = 'ExperiÃªncia', col = 'red',
     ylim = c(min(to.plot$pr.prob - 2*to.plot$pr.se),
              max(to.plot$pr.prob + 2*to.plot$pr.se)))

lines(y = to.plot$pr.prob - 2*to.plot$pr.se,x = c(2:66),
      col = 'blue')
lines(y = to.plot$pr.prob + 2*to.plot$pr.se,x = c(2:66),
      col = 'blue')

plot(to.plot$wh.prob ~ c(2:66), type = 'l',
     main = 'White Collar', ylab = 'Probabilidade',
     xlab = 'ExperiÃªncia', col = 'red',
     ylim = c(min(to.plot$wh.prob - 2*to.plot$wh.se),
              max(to.plot$wh.prob + 2*to.plot$wh.se)))

lines(y = to.plot$wh.prob - 2*to.plot$wh.se,x = c(2:66),
      col = 'blue')
lines(y = to.plot$wh.prob + 2*to.plot$wh.se,x = c(2:66),
      col = 'blue')


